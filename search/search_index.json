{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This is a collection of analysis tools to study RNA localization from single molecule FISH (smFISH) images. These tools were developed in the context of RNA localization in liver , but can likely be applied for different questions as well. We provide different analysis workflows (listed in the banners above ). For each we specify the required installations, and detailed Instructions for how run these workflows and what results are typically obtained. General analysis workflow The tools require a very specific data organziation that we specify RNA detection is performed with FISH-quant in Matlab. Post-processing is performed with ImJoy plugins. ImJoy plugins \u00b6 Most of the workflows are implemented as ImJoy plugins , with a simple interface to specify the different workflow parameters. We describe in a dedicated section how to use ImJoy and the Plugin engine to run these plugins. Quick summary for how to connect ImJoy to Jupyter engine Open anaconda terminal . Activate environment : conda activate rna-loc-liver Start Jupyter engine : imjoy --jupyter Connect ImJoy to Jupyter Engine with \ud83d\ude80 button. We also provide Jupyter notebooks for these workflows, which we recommend only for more experienced Python users.","title":"Overview"},{"location":"#imjoy-plugins","text":"Most of the workflows are implemented as ImJoy plugins , with a simple interface to specify the different workflow parameters. We describe in a dedicated section how to use ImJoy and the Plugin engine to run these plugins. Quick summary for how to connect ImJoy to Jupyter engine Open anaconda terminal . Activate environment : conda activate rna-loc-liver Start Jupyter engine : imjoy --jupyter Connect ImJoy to Jupyter Engine with \ud83d\ude80 button. We also provide Jupyter notebooks for these workflows, which we recommend only for more experienced Python users.","title":"ImJoy plugins"},{"location":"cell-environment/","text":"Cell environment \u00b6 In this workflow, expression levels are measured in equi-distant zones around user-defined regions, e.g. cells. As input the workflow requires: FISH-quant results file: positions of RNAs. ImJoy annotation files: positions of cells. Summary of analysis workflow \u00b6 For each RNA, the distance to every regions is calculated and the RNA is assigned to the closest region. The user also defines the spacing of equi-distant zones around each region. For each region, the number of RNAs for each zone is computed. Additionally, the number of pixels in each zone, i.e. it's area is calculated. If required, this can be used to normalized the RNA counts, i.e. to to correct for the large size of regions that are are further away. Required tools \u00b6 FISH-quant for RNA detection \u00b6 For more information, Please visit the dedicated section here . ImJoy Plugins \u00b6 These plugins have to be installed only once, after installation they will be available in the dedicated ImJoy workspace: liver-rna-loc When pressing on the links below, ImJoy will open in your browser (best in Chrome) and you will be asked to confirm the installation with a dialog as shown below. After confirmation, the plugin and additional auxiliary plugins will be installed. ImageAnnotator : annotate your images. Install from here. CellEnvironment : calculate expression gradient. Install from here. Alternatively, you can also use the provided Jupyter notebook. Jupyter notebook \u00b6 To perform the calculation of the expression gradients, we also provide a Jupyter notebook cell_environment.ipynb , which can be found on GitHub in the folder notebooks . Data \u00b6 Data organisation \u00b6 This workflow permits batch-processing of a large number of files, but requires a strict data-organization Top folder called acquisition . A subfolder for each experimental condition, i.e. cond_1 for the example data. Each sample (usually a field of view) is in a separate folder, e.g. named sample_1 , sample_2 , ... .Each sample folder can contain images of multiple channels. FQ result files are in the same folder. A folder can contain multiple FQ results for different channels. An annotation file with the outlines cells (ending with annotation.json ). See below for more details. In the example below, a folder contains the annotations ( annotation.json ), two different channels ( ...green.tif , ...red.tif , ...blue.tif ), the FQ outline file ( ...outline.txt ), the FQ results for the red channels ...spots.txt , and an annotation file ( annotation.json ). Please note that you can have only one annotation file per sample folder . You can create it by visualizing any of the channels, but the same annotations will be used for each FQ results file in this folder. \u251c\u2500 data__cell_environment/ \u2502 \u251c\u2500 acquisition \u2502 \u2502 \u251c\u2500 cond_1 \u2502 \u2502 \u2502 \u251c\u2500 sample_1 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_annotation.json \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_red_spots.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_red_outline.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_green.tif \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_red.tif \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_blue.tif \u2502 \u2502 \u2502 \u251c\u2500 sample_2 \u2502 \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u251c\u2500 cond_1 \u2502 \u2502 \u2502 \u251c\u2500 sample_1 \u2502 \u2502 \u2502 \u251c\u2500 ... \u2502 \u251c\u2500 analysis \u2502 \u2502 \u251c\u2500 cond_1 \u2502 \u2502 \u2502 \u251c\u2500 sample_1 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 analysis__cell_env \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_red_spots \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 histogram__PIX.csv \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 histogram__RNA.csv \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 histogram__RNA_norm.csv \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 per_region \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 hist__reg_0.png \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 histogram__reg_0.csv \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u251c\u2500 ... Demo data \u00b6 You can find already processed demo data here. The outline cells are macrophages, and have the label Mac . TODO: upon publication, demo data will be moved to Zenodo. Analysis workflow \u00b6 1. RNA detection with FQ \u00b6 For more details, please consult the dedicated section here . 2. Annotation of cells \u00b6 For this workflow, all cells that should be analyze have to be manually annotated in ImJoy with one annotation type. We recommend naming this annotation Cells , but other names can be used as well (but you have to update the default value in the analysis scripts as described below). For more details, please consult the dedicated section here . 3. Calculate density profiles \u00b6 You can run this analysis either with the dedicated ImJoy plugin or the provided Jupyter notebook. In either case, you need to have a local installation of Python. For more information consult the dedicated section here . 4. Location to store results \u00b6 The results will be saved in a dedicated folder analysis__cell_env . Here, a dedicated folder for each spot detection result will be created and named with the name of the FQ results file. Different options exist to define where this folder will be created: You can define an absolute path name . This path will be used to store the data. You can define a replacement operation where parts of the path name of the results, will be replaced with another string. This is convenient when wanting to store the results in a different location than the raw data. Such a replacement operation is specified with a string where the old_string is separated by the new_string with a >> , e.g. the string acquisition>>analysis indicates that not a complete path is provided, but that a string in the provided data folder will be replaced. More specifically, the string acquisition will be replaced by analysis . Analysis in ImJoy \u00b6 If you use Imjoy , you need to install the Jupyter engine . The first installation might take a bit of time, since the necessary Python environments on the plugin engine are created. Once installed, you will see in the plugin sidebar, where you can launch the analysis: Paste the full name of the folder that should be processed. This folder will be recursively searched and each subfolder containing an annotation file will be processed. If needed, change the analysis parameters (see Table below), and press on plugin name in blue to launch the analysis, Option Type Default Description Path DATA str Full path to folder that should be scanned for annotation files. PATH Save str Where results should be saved (see above). Region label str Cells Label of the annotated regions. Annotation file str annotation.json Name of the ImJoy annotation file. Hist [min] int 0 Minimum value of histogram to summarize enrichment (in pixel). Hist [max] int 300 Maximum value of histogram to summarize enrichment (in pixel). Hist [bin] int 50 Bin size (in pixel). The plugin will then analyse all sample folders containing an annotation file. Progress can be monitored in the plugin log, accessible via the i next to the plugin name. Progress is reported in the plugin log (accessible with the 'i' symbol next to the plugin name) and the ImJoy progress bar. With Jupyter notebook \u00b6 Once you have your conda environment installed as described in the Overview section, you can open the Jupyter notebook ( cell_environment.ipynb , which can be found on GitHub in the folder notebooks . You have to execute the first cell to import the analysis package. The second cell allows you to Define the folder containing your data. Defining the parameters described above for the analysis. Executing the cell, will launch the analysis workflow as described above. 4. Generated result files \u00b6 The function will create a number of result files, which are stored in the subfolder analysis__cell_env . For each FQ result file, a separate subfolder with name of this file is created. In this folder the different histograms are summarized: histogram__PIX.csv . Contains PIXEL histograms for all regions, e.g. number of pixels in the defined equi-distant zones around the regions. These values are used for renormalization. First column is the center of histogram bin (in pixel). histogram__RNA.csv . Contains RNA counts per equi-distant zone for all regions. histogram__RNA_norm.csv . Contains renormalized RNA counts per equi-distant zone for all regions. In this folder, results for each region are stored Results files have the full name of the FQ file with the following prefixes histogram__reg_i.csv , histograms for region i . Contains the spatial expression gradient as a table: 1st col: center of histogram bins (in pixel). 2nd col: RNA counts 3rd col: Pixel counts 4th col: Normalize counts. histogram_summary__reg_i.png , summary image of for region i . First row shows smFISH image, mask of region, distance transform (distance from region). Second row shows the raw histograms for RNAs and pixels, as well as the renormalized histogram.","title":"Cell environment"},{"location":"cell-environment/#cell-environment","text":"In this workflow, expression levels are measured in equi-distant zones around user-defined regions, e.g. cells. As input the workflow requires: FISH-quant results file: positions of RNAs. ImJoy annotation files: positions of cells.","title":"Cell environment"},{"location":"cell-environment/#summary-of-analysis-workflow","text":"For each RNA, the distance to every regions is calculated and the RNA is assigned to the closest region. The user also defines the spacing of equi-distant zones around each region. For each region, the number of RNAs for each zone is computed. Additionally, the number of pixels in each zone, i.e. it's area is calculated. If required, this can be used to normalized the RNA counts, i.e. to to correct for the large size of regions that are are further away.","title":"Summary of analysis workflow"},{"location":"cell-environment/#required-tools","text":"","title":"Required tools"},{"location":"cell-environment/#fish-quant-for-rna-detection","text":"For more information, Please visit the dedicated section here .","title":"FISH-quant for RNA detection"},{"location":"cell-environment/#imjoy-plugins","text":"These plugins have to be installed only once, after installation they will be available in the dedicated ImJoy workspace: liver-rna-loc When pressing on the links below, ImJoy will open in your browser (best in Chrome) and you will be asked to confirm the installation with a dialog as shown below. After confirmation, the plugin and additional auxiliary plugins will be installed. ImageAnnotator : annotate your images. Install from here. CellEnvironment : calculate expression gradient. Install from here. Alternatively, you can also use the provided Jupyter notebook.","title":"ImJoy Plugins"},{"location":"cell-environment/#jupyter-notebook","text":"To perform the calculation of the expression gradients, we also provide a Jupyter notebook cell_environment.ipynb , which can be found on GitHub in the folder notebooks .","title":"Jupyter notebook"},{"location":"cell-environment/#data","text":"","title":"Data"},{"location":"cell-environment/#data-organisation","text":"This workflow permits batch-processing of a large number of files, but requires a strict data-organization Top folder called acquisition . A subfolder for each experimental condition, i.e. cond_1 for the example data. Each sample (usually a field of view) is in a separate folder, e.g. named sample_1 , sample_2 , ... .Each sample folder can contain images of multiple channels. FQ result files are in the same folder. A folder can contain multiple FQ results for different channels. An annotation file with the outlines cells (ending with annotation.json ). See below for more details. In the example below, a folder contains the annotations ( annotation.json ), two different channels ( ...green.tif , ...red.tif , ...blue.tif ), the FQ outline file ( ...outline.txt ), the FQ results for the red channels ...spots.txt , and an annotation file ( annotation.json ). Please note that you can have only one annotation file per sample folder . You can create it by visualizing any of the channels, but the same annotations will be used for each FQ results file in this folder. \u251c\u2500 data__cell_environment/ \u2502 \u251c\u2500 acquisition \u2502 \u2502 \u251c\u2500 cond_1 \u2502 \u2502 \u2502 \u251c\u2500 sample_1 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_annotation.json \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_red_spots.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_red_outline.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_green.tif \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_red.tif \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_blue.tif \u2502 \u2502 \u2502 \u251c\u2500 sample_2 \u2502 \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u251c\u2500 cond_1 \u2502 \u2502 \u2502 \u251c\u2500 sample_1 \u2502 \u2502 \u2502 \u251c\u2500 ... \u2502 \u251c\u2500 analysis \u2502 \u2502 \u251c\u2500 cond_1 \u2502 \u2502 \u2502 \u251c\u2500 sample_1 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 analysis__cell_env \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 sample_1_red_spots \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 histogram__PIX.csv \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 histogram__RNA.csv \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 histogram__RNA_norm.csv \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 per_region \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 hist__reg_0.png \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 histogram__reg_0.csv \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u251c\u2500 ...","title":"Data organisation"},{"location":"cell-environment/#demo-data","text":"You can find already processed demo data here. The outline cells are macrophages, and have the label Mac . TODO: upon publication, demo data will be moved to Zenodo.","title":"Demo data"},{"location":"cell-environment/#analysis-workflow","text":"","title":"Analysis workflow"},{"location":"cell-environment/#1-rna-detection-with-fq","text":"For more details, please consult the dedicated section here .","title":"1. RNA detection with FQ"},{"location":"cell-environment/#2-annotation-of-cells","text":"For this workflow, all cells that should be analyze have to be manually annotated in ImJoy with one annotation type. We recommend naming this annotation Cells , but other names can be used as well (but you have to update the default value in the analysis scripts as described below). For more details, please consult the dedicated section here .","title":"2. Annotation of cells"},{"location":"cell-environment/#3-calculate-density-profiles","text":"You can run this analysis either with the dedicated ImJoy plugin or the provided Jupyter notebook. In either case, you need to have a local installation of Python. For more information consult the dedicated section here .","title":"3. Calculate density profiles"},{"location":"cell-environment/#4-location-to-store-results","text":"The results will be saved in a dedicated folder analysis__cell_env . Here, a dedicated folder for each spot detection result will be created and named with the name of the FQ results file. Different options exist to define where this folder will be created: You can define an absolute path name . This path will be used to store the data. You can define a replacement operation where parts of the path name of the results, will be replaced with another string. This is convenient when wanting to store the results in a different location than the raw data. Such a replacement operation is specified with a string where the old_string is separated by the new_string with a >> , e.g. the string acquisition>>analysis indicates that not a complete path is provided, but that a string in the provided data folder will be replaced. More specifically, the string acquisition will be replaced by analysis .","title":"4. Location to store results"},{"location":"cell-environment/#analysis-in-imjoy","text":"If you use Imjoy , you need to install the Jupyter engine . The first installation might take a bit of time, since the necessary Python environments on the plugin engine are created. Once installed, you will see in the plugin sidebar, where you can launch the analysis: Paste the full name of the folder that should be processed. This folder will be recursively searched and each subfolder containing an annotation file will be processed. If needed, change the analysis parameters (see Table below), and press on plugin name in blue to launch the analysis, Option Type Default Description Path DATA str Full path to folder that should be scanned for annotation files. PATH Save str Where results should be saved (see above). Region label str Cells Label of the annotated regions. Annotation file str annotation.json Name of the ImJoy annotation file. Hist [min] int 0 Minimum value of histogram to summarize enrichment (in pixel). Hist [max] int 300 Maximum value of histogram to summarize enrichment (in pixel). Hist [bin] int 50 Bin size (in pixel). The plugin will then analyse all sample folders containing an annotation file. Progress can be monitored in the plugin log, accessible via the i next to the plugin name. Progress is reported in the plugin log (accessible with the 'i' symbol next to the plugin name) and the ImJoy progress bar.","title":"Analysis in ImJoy"},{"location":"cell-environment/#with-jupyter-notebook","text":"Once you have your conda environment installed as described in the Overview section, you can open the Jupyter notebook ( cell_environment.ipynb , which can be found on GitHub in the folder notebooks . You have to execute the first cell to import the analysis package. The second cell allows you to Define the folder containing your data. Defining the parameters described above for the analysis. Executing the cell, will launch the analysis workflow as described above.","title":"With Jupyter notebook"},{"location":"cell-environment/#4-generated-result-files","text":"The function will create a number of result files, which are stored in the subfolder analysis__cell_env . For each FQ result file, a separate subfolder with name of this file is created. In this folder the different histograms are summarized: histogram__PIX.csv . Contains PIXEL histograms for all regions, e.g. number of pixels in the defined equi-distant zones around the regions. These values are used for renormalization. First column is the center of histogram bin (in pixel). histogram__RNA.csv . Contains RNA counts per equi-distant zone for all regions. histogram__RNA_norm.csv . Contains renormalized RNA counts per equi-distant zone for all regions. In this folder, results for each region are stored Results files have the full name of the FQ file with the following prefixes histogram__reg_i.csv , histograms for region i . Contains the spatial expression gradient as a table: 1st col: center of histogram bins (in pixel). 2nd col: RNA counts 3rd col: Pixel counts 4th col: Normalize counts. histogram_summary__reg_i.png , summary image of for region i . First row shows smFISH image, mask of region, distance transform (distance from region). Second row shows the raw histograms for RNAs and pixels, as well as the renormalized histogram.","title":"4. Generated result files"},{"location":"expression-gradient/","text":"Expression gradient analysis \u00b6 In this workflow, the spatial expression gradient between two reference regions are created. The distances are renormalised such that results from different images can be more easily be compared. As input the workflow requires: FISH-quant results file: created with FISH-quant. ImJoy annotation files: annotations of the two reference regions. Summary of analysis workflow \u00b6 The expression gradient is calculated as follows In the analysis, the distance for RNA from the first reference region is calculated (the shortest distance between the RNA and the polygon defining this region). Negative distances mean that the RNA is inside, positive that the RNA is outside. These distances are then renormalised with the shortest distance between the center of mass of the second region and the polygon of the first region. Distances are then summarised in histograms with bins of width 0.1 between the minimum and maximum renormalised distance measurements. These counts are then further renormalised to consider the actual contained area in the image for a given distance. This is done by calculating the distance transform of the image with respect to region 1. These values are treated distance measurements, and treated as described for the RNA distance measurements. The obtained histogram counts are used to normalise the RNA distance counts. Lastly, the histogram is such that frequencies sum up to 1. Required tools \u00b6 ImJoy Plugins \u00b6 These plugins have to be installed only once, after installation they will be available in the dedicated ImJoy workspace: liver-rna-loc Pressing on the links below, will open ImJoy in your browser (best in Chrome) and allow you to install the required plugins. You will be asked to confirm the installation with a dialog as shown below. After confirmation, the plugins will be installed together with additional auxiliary plugins. ImageAnnotator : annotate your images. Install from here. ExpGradient : calculate expression gradient. Install from here. Jupyter notebook \u00b6 To perform the calculation of the expression gradients, we also provide a Jupyter notebook expression_gradient.ipynb , which can be found on GitHub in the folder notebooks . Data \u00b6 Data organisation \u00b6 This workflow requires that data is organised in the following away A parental folder contains all sample folders, e.g. data__expression_gradient for the example data. Each sample (usually a field of view) is in a separate folder, e.g. named sample_1 , sample_2 , .... Each sample folder can contain images of multiple channels. FQ result file are in the same folder. A folder can contain FQ results for different channels. An annotation file with the two reference regions ( annotation.json ). See below for more details. In the example below, a folder contains the annotations ( annotation.json ), two different channels ( ...(green).tif and ...(red).tif ), the FQ results for both channels ....txt , and an annotation file ( annotation.json ). Please note that you can have only one annotation file per sample folder . You can generate it based on any of the channels, but the same annnotations will be used for each FQ results file in this folder. \u251c\u2500 data__expression_gradient/ \u2502 \u251c\u2500 sample_1 \u2502 \u2502 \u251c\u2500 annotation.json \u2502 \u2502 \u251c\u2500 sample_1_green_outline_spots_181018.txt \u2502 \u2502 \u251c\u2500 sample_1_green.tif \u2502 \u2502 \u251c\u2500 sample_1_red_outline_spots_181017.txt \u2502 \u2502 \u251c\u2500 sample_1_red.tif \u2502 \u251c\u2500 sample_2 \u2502 \u2502 \u251c\u2500 ... Demo data \u00b6 You can find already processed demo data here. TODO: upon publication, demo data will be moved to Zenodo. Analysis \u00b6 1. RNA detection with FQ \u00b6 Please consult the dedicated section here for more details. 2. Annotation of reference regions \u00b6 Please consult the dedicated section here for more details. For this workflow, you need TWO different annotations Central vein , we recommend naming it CV . Portal lobe , we recommend naming it PL . 3. Calculate density profiles \u00b6 You can run this analysis either with the provided code in the Jupyter notebook, or use ImJoy. Analysis in ImJoy \u00b6 If you use ImJoy , you need to install the Python plugin engine . The first installation might take a bit of time, since the necessary Python environments are created. Once installed, you will see in the the plugin in the sidebar. Before using it, you have to specify the labels of the two reference regions. To access the plugin parameters, press on the arrow down symbol next to the plugin name. In the example below the labels CV and PL are defined for the first and second region, respectively. Then you can press on the plugin name to execute the plugin. In a dialog, you will be asked to specify a folder, please select the parental folder containing the different sample folders. The plugin will then analyse all sample folders containing an annotation file. The regions in this file will then be used to establish the spatial expression gradient between these two regions. Progress is reported in the plugin log (accessible with the 'i' symbol next to the plugin name) and the ImJoy progress bar. With Jupyter notebook \u00b6 Once you have your conda environment installed as described in the Overview section, you can open the Jupyter notebook and analyze your data. You have to execute the first cell to load the necessary code. The second cell allows you to Define the folder containing your data. Defining the labels for the two annotated reference regions. Executing the cell, will launch the analysis workflow. described above. 4. Generated result files \u00b6 The function will create a number of result files, which are stored in the subfolder analysis__exprGradient . Results files have the full name of the FQ file with the following prefixes _summary_density (PNG file). Contains plots of expression density plots. Cells are filled with pixel values corresponding to their expression level. _summary_gradient (PNG file). Contains summary plots for the spatial gradients between two the two reference points (the first plot shown on this page). hist_expression (tab delimited text file). Contains the spatial expression gradient as a table: 1st col: normalised distance, 2nd col: normalised counts by number of pixels (4th col) 3rd col: RNA counts 4th col: number of pixels in the image within range (for normalisation) img_density (16bit tif file). Contains the expression density plots. The pixel value of the cell corresponds to the number of RNAs in this cell. No outlines are shown. Files can be rendered with Fiji and an adequate look-up table. img_density_outline (16 bit tif file). Contains the expression density plot and the cell outlines. The outlines of the cells are set to the maximum RNA count in the image. This guarantees that the outlines can be seen. img_outline (8 bit image). Outlines of all cells in the image.","title":"Expression gradient"},{"location":"expression-gradient/#expression-gradient-analysis","text":"In this workflow, the spatial expression gradient between two reference regions are created. The distances are renormalised such that results from different images can be more easily be compared. As input the workflow requires: FISH-quant results file: created with FISH-quant. ImJoy annotation files: annotations of the two reference regions.","title":"Expression gradient analysis"},{"location":"expression-gradient/#summary-of-analysis-workflow","text":"The expression gradient is calculated as follows In the analysis, the distance for RNA from the first reference region is calculated (the shortest distance between the RNA and the polygon defining this region). Negative distances mean that the RNA is inside, positive that the RNA is outside. These distances are then renormalised with the shortest distance between the center of mass of the second region and the polygon of the first region. Distances are then summarised in histograms with bins of width 0.1 between the minimum and maximum renormalised distance measurements. These counts are then further renormalised to consider the actual contained area in the image for a given distance. This is done by calculating the distance transform of the image with respect to region 1. These values are treated distance measurements, and treated as described for the RNA distance measurements. The obtained histogram counts are used to normalise the RNA distance counts. Lastly, the histogram is such that frequencies sum up to 1.","title":"Summary of analysis workflow"},{"location":"expression-gradient/#required-tools","text":"","title":"Required tools"},{"location":"expression-gradient/#imjoy-plugins","text":"These plugins have to be installed only once, after installation they will be available in the dedicated ImJoy workspace: liver-rna-loc Pressing on the links below, will open ImJoy in your browser (best in Chrome) and allow you to install the required plugins. You will be asked to confirm the installation with a dialog as shown below. After confirmation, the plugins will be installed together with additional auxiliary plugins. ImageAnnotator : annotate your images. Install from here. ExpGradient : calculate expression gradient. Install from here.","title":"ImJoy Plugins"},{"location":"expression-gradient/#jupyter-notebook","text":"To perform the calculation of the expression gradients, we also provide a Jupyter notebook expression_gradient.ipynb , which can be found on GitHub in the folder notebooks .","title":"Jupyter notebook"},{"location":"expression-gradient/#data","text":"","title":"Data"},{"location":"expression-gradient/#data-organisation","text":"This workflow requires that data is organised in the following away A parental folder contains all sample folders, e.g. data__expression_gradient for the example data. Each sample (usually a field of view) is in a separate folder, e.g. named sample_1 , sample_2 , .... Each sample folder can contain images of multiple channels. FQ result file are in the same folder. A folder can contain FQ results for different channels. An annotation file with the two reference regions ( annotation.json ). See below for more details. In the example below, a folder contains the annotations ( annotation.json ), two different channels ( ...(green).tif and ...(red).tif ), the FQ results for both channels ....txt , and an annotation file ( annotation.json ). Please note that you can have only one annotation file per sample folder . You can generate it based on any of the channels, but the same annnotations will be used for each FQ results file in this folder. \u251c\u2500 data__expression_gradient/ \u2502 \u251c\u2500 sample_1 \u2502 \u2502 \u251c\u2500 annotation.json \u2502 \u2502 \u251c\u2500 sample_1_green_outline_spots_181018.txt \u2502 \u2502 \u251c\u2500 sample_1_green.tif \u2502 \u2502 \u251c\u2500 sample_1_red_outline_spots_181017.txt \u2502 \u2502 \u251c\u2500 sample_1_red.tif \u2502 \u251c\u2500 sample_2 \u2502 \u2502 \u251c\u2500 ...","title":"Data organisation"},{"location":"expression-gradient/#demo-data","text":"You can find already processed demo data here. TODO: upon publication, demo data will be moved to Zenodo.","title":"Demo data"},{"location":"expression-gradient/#analysis","text":"","title":"Analysis"},{"location":"expression-gradient/#1-rna-detection-with-fq","text":"Please consult the dedicated section here for more details.","title":"1. RNA detection with FQ"},{"location":"expression-gradient/#2-annotation-of-reference-regions","text":"Please consult the dedicated section here for more details. For this workflow, you need TWO different annotations Central vein , we recommend naming it CV . Portal lobe , we recommend naming it PL .","title":"2. Annotation of reference regions"},{"location":"expression-gradient/#3-calculate-density-profiles","text":"You can run this analysis either with the provided code in the Jupyter notebook, or use ImJoy.","title":"3. Calculate density profiles"},{"location":"expression-gradient/#analysis-in-imjoy","text":"If you use ImJoy , you need to install the Python plugin engine . The first installation might take a bit of time, since the necessary Python environments are created. Once installed, you will see in the the plugin in the sidebar. Before using it, you have to specify the labels of the two reference regions. To access the plugin parameters, press on the arrow down symbol next to the plugin name. In the example below the labels CV and PL are defined for the first and second region, respectively. Then you can press on the plugin name to execute the plugin. In a dialog, you will be asked to specify a folder, please select the parental folder containing the different sample folders. The plugin will then analyse all sample folders containing an annotation file. The regions in this file will then be used to establish the spatial expression gradient between these two regions. Progress is reported in the plugin log (accessible with the 'i' symbol next to the plugin name) and the ImJoy progress bar.","title":"Analysis in ImJoy"},{"location":"expression-gradient/#with-jupyter-notebook","text":"Once you have your conda environment installed as described in the Overview section, you can open the Jupyter notebook and analyze your data. You have to execute the first cell to load the necessary code. The second cell allows you to Define the folder containing your data. Defining the labels for the two annotated reference regions. Executing the cell, will launch the analysis workflow. described above.","title":"With Jupyter notebook"},{"location":"expression-gradient/#4-generated-result-files","text":"The function will create a number of result files, which are stored in the subfolder analysis__exprGradient . Results files have the full name of the FQ file with the following prefixes _summary_density (PNG file). Contains plots of expression density plots. Cells are filled with pixel values corresponding to their expression level. _summary_gradient (PNG file). Contains summary plots for the spatial gradients between two the two reference points (the first plot shown on this page). hist_expression (tab delimited text file). Contains the spatial expression gradient as a table: 1st col: normalised distance, 2nd col: normalised counts by number of pixels (4th col) 3rd col: RNA counts 4th col: number of pixels in the image within range (for normalisation) img_density (16bit tif file). Contains the expression density plots. The pixel value of the cell corresponds to the number of RNAs in this cell. No outlines are shown. Files can be rendered with Fiji and an adequate look-up table. img_density_outline (16 bit tif file). Contains the expression density plot and the cell outlines. The outlines of the cells are set to the maximum RNA count in the image. This guarantees that the outlines can be seen. img_outline (8 bit image). Outlines of all cells in the image.","title":"4. Generated result files"},{"location":"imjoy-annotation/","text":"Image annotation with ImJoy \u00b6 This is performed with the Annotator plugin running in ImJoy. Note that annotation can only be performed on 2D images . If your images are 3D, please convert them first to 2D images, e.g. with a maximum intensity projection. To annotate your images , follow these steps Open the annotation plugin by clicking on the plugin name ImageAnnotator The plugin will open with a default image and you have to load your own data . Press on the File dropdown menu in the upper right corner Select Import Samples In the new dialog press Choose Files and then Select Local Files . In case your files are on a different drive, you can specify the drive from Options and Go to folder . In the dialog, select the parental folder containing all sample folders. ImJoy will display a dialog saying \"This will upload ....\", confirm. Your data only be \"uploaded\" to your local browser BUT not on an external website. This will populate the interface with all sample folders. For each folder, you see a little icon representing a file being present in the folder. You then have to set a filter on the file-name for the channel which will be read into the Annotator plugin. For this you set a name for the channel, e.g. FISH , and the identifier of this image, e.g. green.tif . Press Add Channel to add this channel. You then see this channel as an additional entry in the interface. Press Import to open the Annotator with the specified files. You then specify your annotation: from the Annotation dropdown menu, you can specify which annotations you want to perform. By pressing New Marker you can specify an new annotation type. You can define its name, the colour in which it will show, and what type (use Polygon). Once you defined the annotation types, you can annotate your image. Then select which file you want to annotate (from the File dropdown menu), and annotate the two different regions. To annotate, press on one of the annotation types, go to the image, and start annotating. For a polygon, simply press the mouse button, draw your region and release once your are done. The example below shows two annotation types, CV and PL. Once you are done, you can export the annotations from the Exports dropdown menu and selecting the All annotations option. The annotations will be saved in the default download folder of your browser as a zip file. You can then unzip this file. It contains the same folder structure as your original parental folder. Each sample folder contains a file annotation.json with the annotations that your created for this sample. You can then simply copy the sample folders and paste them in the parental folder containing your data (with Windows explorer or Mac OS finder). When asked if you want to merge the folders, confirm.","title":"Image annotation with ImJoy"},{"location":"imjoy-annotation/#image-annotation-with-imjoy","text":"This is performed with the Annotator plugin running in ImJoy. Note that annotation can only be performed on 2D images . If your images are 3D, please convert them first to 2D images, e.g. with a maximum intensity projection. To annotate your images , follow these steps Open the annotation plugin by clicking on the plugin name ImageAnnotator The plugin will open with a default image and you have to load your own data . Press on the File dropdown menu in the upper right corner Select Import Samples In the new dialog press Choose Files and then Select Local Files . In case your files are on a different drive, you can specify the drive from Options and Go to folder . In the dialog, select the parental folder containing all sample folders. ImJoy will display a dialog saying \"This will upload ....\", confirm. Your data only be \"uploaded\" to your local browser BUT not on an external website. This will populate the interface with all sample folders. For each folder, you see a little icon representing a file being present in the folder. You then have to set a filter on the file-name for the channel which will be read into the Annotator plugin. For this you set a name for the channel, e.g. FISH , and the identifier of this image, e.g. green.tif . Press Add Channel to add this channel. You then see this channel as an additional entry in the interface. Press Import to open the Annotator with the specified files. You then specify your annotation: from the Annotation dropdown menu, you can specify which annotations you want to perform. By pressing New Marker you can specify an new annotation type. You can define its name, the colour in which it will show, and what type (use Polygon). Once you defined the annotation types, you can annotate your image. Then select which file you want to annotate (from the File dropdown menu), and annotate the two different regions. To annotate, press on one of the annotation types, go to the image, and start annotating. For a polygon, simply press the mouse button, draw your region and release once your are done. The example below shows two annotation types, CV and PL. Once you are done, you can export the annotations from the Exports dropdown menu and selecting the All annotations option. The annotations will be saved in the default download folder of your browser as a zip file. You can then unzip this file. It contains the same folder structure as your original parental folder. Each sample folder contains a file annotation.json with the annotations that your created for this sample. You can then simply copy the sample folders and paste them in the parental folder containing your data (with Windows explorer or Mac OS finder). When asked if you want to merge the folders, confirm.","title":"Image annotation with ImJoy"},{"location":"licence/","text":"License \u00b6 MIT License Copyright \u00a9 Florian MUELLER Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Licence"},{"location":"licence/#license","text":"MIT License Copyright \u00a9 Florian MUELLER Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"rna-detection/","text":"RNA detection with FISH-quant \u00b6 FISH-quant \u00b6 FISH-quant is a Matlab toolbox to localize RNAs in 3D from smFISH images. Detection of individual RNAs \u00b6 Below only a quick summary of the analysis steps is presented. For more details consult the FQ manual. . Open FQ Set analysis folder to folder containing the image that should be analysed: Menu Folder > Set root folder ) Open image that should be analysed. [Optional] Draw outline of embryo / cells / structure of interest. If you omit t his step, RNAs will be detected in the entire image. Open dedicated interface: Button Define outlines Draw a new cell: Button New cell Save outline: Button Quick-save Return to main FQ: Button Finished Filter image (default filter with LoG works usually well). Inspect image. On the right part of the interface select Filtered image , disable outline , and double click on the image. This will show a maximum intensity projection of the filtered image in a separate window. Here, you can change the contrast and zoom. In order to determine an appropriate threshold in the next step, determine a generous range of intensities range corresponding to the individual RNA molecules. Set pre-detection settings . FQ will test how many RNAs are detected with a range of user-defined intensity thresholds (based on the manual inspection of the image from above). Open dedicated interface: Button Detect In the user-dialog change the first two parameter: minimum and maximum threshold to test. We usually use a minimum value that\u2019s somewhat lower than the lowest RNAs to also consider intensity value corresponding to background. FQ will calculate the number of detected RNAs for a range of values in this interval. Depending on the size of the image, this can take a little while. Once done, a plot with the number of detected RNAs as a function of the different thresholds is shown. If the specified range is not appropriate, it can be changed in this interface the computation be repeated. Ideally, this curve shows a plateau for a value range corresponding to a good detection threshold. If that\u2019s not the case, a reasonable value corresponding to a visual assessment of what individual RNAs are should be chosen. A pre-detection with a given detection threshold can be perform and the results be inspected in a separate window. One other parameter that could be important to adjust is the cropping region around each RNA that is considered for analysis and fitting. Reducing this size allows sometimes to better detect closely spaced RNAs but at the cost of an imprecision in the fit. For most applications a value of +/- 2 voxels in XY and Z are a good compromise. Once you are satisfied with the settings press on Perform detection for all cells to return the main window. Press button Fit to fit each detected spot with a 3D Gaussian function. [Optional]. You can set threshold values for the different fitting parameters, e.g. remove spots with very small or very large standard deviations. You can now save the detection settings: [FQ] Main > Save > Save detection settings . As a file-name specify FQ__settings_MATURE.txt If you are satisfied with these detection results, you can save them directly: [FQ] Main > Save > Detection spots [All] .","title":"RNA detection with FQ"},{"location":"rna-detection/#rna-detection-with-fish-quant","text":"","title":"RNA detection with FISH-quant"},{"location":"rna-detection/#fish-quant","text":"FISH-quant is a Matlab toolbox to localize RNAs in 3D from smFISH images.","title":"FISH-quant"},{"location":"rna-detection/#detection-of-individual-rnas","text":"Below only a quick summary of the analysis steps is presented. For more details consult the FQ manual. . Open FQ Set analysis folder to folder containing the image that should be analysed: Menu Folder > Set root folder ) Open image that should be analysed. [Optional] Draw outline of embryo / cells / structure of interest. If you omit t his step, RNAs will be detected in the entire image. Open dedicated interface: Button Define outlines Draw a new cell: Button New cell Save outline: Button Quick-save Return to main FQ: Button Finished Filter image (default filter with LoG works usually well). Inspect image. On the right part of the interface select Filtered image , disable outline , and double click on the image. This will show a maximum intensity projection of the filtered image in a separate window. Here, you can change the contrast and zoom. In order to determine an appropriate threshold in the next step, determine a generous range of intensities range corresponding to the individual RNA molecules. Set pre-detection settings . FQ will test how many RNAs are detected with a range of user-defined intensity thresholds (based on the manual inspection of the image from above). Open dedicated interface: Button Detect In the user-dialog change the first two parameter: minimum and maximum threshold to test. We usually use a minimum value that\u2019s somewhat lower than the lowest RNAs to also consider intensity value corresponding to background. FQ will calculate the number of detected RNAs for a range of values in this interval. Depending on the size of the image, this can take a little while. Once done, a plot with the number of detected RNAs as a function of the different thresholds is shown. If the specified range is not appropriate, it can be changed in this interface the computation be repeated. Ideally, this curve shows a plateau for a value range corresponding to a good detection threshold. If that\u2019s not the case, a reasonable value corresponding to a visual assessment of what individual RNAs are should be chosen. A pre-detection with a given detection threshold can be perform and the results be inspected in a separate window. One other parameter that could be important to adjust is the cropping region around each RNA that is considered for analysis and fitting. Reducing this size allows sometimes to better detect closely spaced RNAs but at the cost of an imprecision in the fit. For most applications a value of +/- 2 voxels in XY and Z are a good compromise. Once you are satisfied with the settings press on Perform detection for all cells to return the main window. Press button Fit to fit each detected spot with a 3D Gaussian function. [Optional]. You can set threshold values for the different fitting parameters, e.g. remove spots with very small or very large standard deviations. You can now save the detection settings: [FQ] Main > Save > Save detection settings . As a file-name specify FQ__settings_MATURE.txt If you are satisfied with these detection results, you can save them directly: [FQ] Main > Save > Detection spots [All] .","title":"Detection of individual RNAs"},{"location":"tools-imjoy/","text":"ImJoy \u00b6 ImJoy is image processing platform with an easy to use interface running in your browser. While ImJoy is a browser app, NO user data will be transferred over the internet. For best stability, we recommend using Chrome to run the ImJoy app. Some of its main features are: Specific functionality is provided by plugins , which can be installed with simple links. Available plugins are listed in the plugin list on the left part of the interface. Plugins using Python require a Plugin engine to be executed. Installation and usasage is detailed below. ImJoy can have several workspaces . Each workspace can contain multiple plugins and is dedicated to a specific data processing task. Workspaces can be selected from little puzzle symbol in the upper left part of the interface. Basic usage \u00b6 Installing plugins \u00b6 We provide links to install ImJoy plugins for the different workflows. If you press on the installation link, the ImJoy app will open and display a dialog asking if you want to install the specified plugin. To confirm, press the install button. These installation links also specify in which ImJoy workspaces the plugin will be installed. Opening a workspace \u00b6 Once a plugin is installed, ImJoy remembers the workspaces and plugins it contains. If you want to redo an analysis, you simply have to open the ImJoy app and select the appropriate ( fq-segmentation for this package): If updates for the installed plugins are available, you will see a corresponding symbol next to the plugin name. Running Python plugins \u00b6 Most of the provided plugins use Python for data processing. To use these plugins, you have to connect ImJoy to a Plugin engine. For this repository, we use Jupyter notebooks as and engine, which can be installed via Miniconda (see installation instructions below ). Connect Jupyter engine \u00b6 Once installed Jupyter is installed, you can start a Jupyter Notebook in the anaconda terminal, to which ImJoy can connect. Please note that this engine runs on your local machine, so no data-transfer over the internet is taking place. In order to connect a Jupyter engine, you need to specify its url that also contains a token (a passphrase). If you launch a Jupyter notebook for the first time, you have to provide this URL to ImJoy (indicated below with First time only ). After this, ImJoy will remember it. Launch a Jupyter Engine for ImJoy : Start an anaconda terminal . Activate the environment : conda activate rna-loc-liver Start Jupyter engine : imjoy --jupyter First time only : copy the provided URL including the token, e.g. http://127.0.0.1:8888/?token=8b4885e452db1af7cd7b3cfa6c62036cbae46995e473c25e Connect ImJoy to Jupyter Engine : In the ImJoy app, press on the rocket symbol in the upper right corner. First time only : select Add Jupyter-Engine , paste the URL from the step above, and you can give a new name to the engine Subsequent use : press on the pre-defined plugin engine to connect to it (of course you have to launch it first). If this is the only engine, plugins will be automatically connected . You can verify this, by clicking on the puzzle symbol next to the plugin name. Depending on the plugin, installation might take a while, during this period the plugin name will be in red. If yoy have multiple engines, you have to choose on which engine the plugin should be running (more details below ). Managing plugin engines \u00b6 ImJoy remembers the plugin engines it connected to (including the token). You can obtain the list of all registered engines by pressing on the rocket symbol. Connected engines will be shown with their name in black, and a red cross next to the name. Pressing the cross will disconnect ImJoy from the engine, but it will remain in the list. Known engines (but not connected) will be shown with their name in gray, with a little trash symbol next to them. Pressing on the trash symbol will remove the engine. Install Jupyter engine for ImJoy \u00b6 We recommend installing an Miniconda with Python : choose Python 3.7 and your operating system. You can then use the annoconda prompt to excecute the different commands listed below. We further recommend creating a dedicated environment to run code in this analysis package. This guarantess that only necessary code is installed. To create an environment called fq-segmentation , open an anaconda prompt and type (Confirm with y when asked if you want to proceed ( Proceed ([y]/n)? ): conda create --name rna-loc-liver python=3.7 Activate the environment : conda activate rna-loc-liver Install code Jupyter optimized for ImJoy : pip install -U imjoy Trouble-shooting \u00b6 Plugin running on wrong engine \u00b6 You have several options Disconnect or delete the engine the plugin is connecting to (see ) here ). In the plugin menu (clicking on the little puzzle symbol left of the plugin name), select the appropriate engine. Remove conda environment \u00b6 At one point, your conda environment might get corrupted. You can easily remove it, and create a new one Open anaconda terminal Activate base environment : conda activate base Remove fq-segmentation environment : conda env remove --name fq-segmentation Reporting bugs \u00b6 Detailed installation logs are provided in the console of the browser. Information in this log, can facilitate the correction of encountered bugs. When reporting problems with this package, please provide the log copied to text file. To acces the console log in Chrome : In the ImJoy app mouse-right-click. Select Inspect . This will open a new interface on the right size of your browser windows. Select the panel Console and copy the entire content, and paste it to a file. Specify your own Jupyter token \u00b6 You can specify your own token yourtoken imjoy --jupyter --token yourtoken When launched like this, you will not get the full Jupyter URL in the terminal, but http://localhost:8888/?token=... . When copying this link to the ImJoy app for the first time you have to replace the ... by the token you actually specified. The next time you start jupyter with imjoy --jupyter your custom token will be used","title":"ImJoy"},{"location":"tools-imjoy/#imjoy","text":"ImJoy is image processing platform with an easy to use interface running in your browser. While ImJoy is a browser app, NO user data will be transferred over the internet. For best stability, we recommend using Chrome to run the ImJoy app. Some of its main features are: Specific functionality is provided by plugins , which can be installed with simple links. Available plugins are listed in the plugin list on the left part of the interface. Plugins using Python require a Plugin engine to be executed. Installation and usasage is detailed below. ImJoy can have several workspaces . Each workspace can contain multiple plugins and is dedicated to a specific data processing task. Workspaces can be selected from little puzzle symbol in the upper left part of the interface.","title":"ImJoy"},{"location":"tools-imjoy/#basic-usage","text":"","title":"Basic usage"},{"location":"tools-imjoy/#installing-plugins","text":"We provide links to install ImJoy plugins for the different workflows. If you press on the installation link, the ImJoy app will open and display a dialog asking if you want to install the specified plugin. To confirm, press the install button. These installation links also specify in which ImJoy workspaces the plugin will be installed.","title":"Installing plugins"},{"location":"tools-imjoy/#opening-a-workspace","text":"Once a plugin is installed, ImJoy remembers the workspaces and plugins it contains. If you want to redo an analysis, you simply have to open the ImJoy app and select the appropriate ( fq-segmentation for this package): If updates for the installed plugins are available, you will see a corresponding symbol next to the plugin name.","title":"Opening a workspace"},{"location":"tools-imjoy/#running-python-plugins","text":"Most of the provided plugins use Python for data processing. To use these plugins, you have to connect ImJoy to a Plugin engine. For this repository, we use Jupyter notebooks as and engine, which can be installed via Miniconda (see installation instructions below ).","title":"Running Python plugins"},{"location":"tools-imjoy/#connect-jupyter-engine","text":"Once installed Jupyter is installed, you can start a Jupyter Notebook in the anaconda terminal, to which ImJoy can connect. Please note that this engine runs on your local machine, so no data-transfer over the internet is taking place. In order to connect a Jupyter engine, you need to specify its url that also contains a token (a passphrase). If you launch a Jupyter notebook for the first time, you have to provide this URL to ImJoy (indicated below with First time only ). After this, ImJoy will remember it. Launch a Jupyter Engine for ImJoy : Start an anaconda terminal . Activate the environment : conda activate rna-loc-liver Start Jupyter engine : imjoy --jupyter First time only : copy the provided URL including the token, e.g. http://127.0.0.1:8888/?token=8b4885e452db1af7cd7b3cfa6c62036cbae46995e473c25e Connect ImJoy to Jupyter Engine : In the ImJoy app, press on the rocket symbol in the upper right corner. First time only : select Add Jupyter-Engine , paste the URL from the step above, and you can give a new name to the engine Subsequent use : press on the pre-defined plugin engine to connect to it (of course you have to launch it first). If this is the only engine, plugins will be automatically connected . You can verify this, by clicking on the puzzle symbol next to the plugin name. Depending on the plugin, installation might take a while, during this period the plugin name will be in red. If yoy have multiple engines, you have to choose on which engine the plugin should be running (more details below ).","title":"Connect Jupyter engine"},{"location":"tools-imjoy/#managing-plugin-engines","text":"ImJoy remembers the plugin engines it connected to (including the token). You can obtain the list of all registered engines by pressing on the rocket symbol. Connected engines will be shown with their name in black, and a red cross next to the name. Pressing the cross will disconnect ImJoy from the engine, but it will remain in the list. Known engines (but not connected) will be shown with their name in gray, with a little trash symbol next to them. Pressing on the trash symbol will remove the engine.","title":"Managing plugin engines"},{"location":"tools-imjoy/#install-jupyter-engine-for-imjoy","text":"We recommend installing an Miniconda with Python : choose Python 3.7 and your operating system. You can then use the annoconda prompt to excecute the different commands listed below. We further recommend creating a dedicated environment to run code in this analysis package. This guarantess that only necessary code is installed. To create an environment called fq-segmentation , open an anaconda prompt and type (Confirm with y when asked if you want to proceed ( Proceed ([y]/n)? ): conda create --name rna-loc-liver python=3.7 Activate the environment : conda activate rna-loc-liver Install code Jupyter optimized for ImJoy : pip install -U imjoy","title":"Install Jupyter engine for ImJoy"},{"location":"tools-imjoy/#trouble-shooting","text":"","title":"Trouble-shooting"},{"location":"tools-imjoy/#plugin-running-on-wrong-engine","text":"You have several options Disconnect or delete the engine the plugin is connecting to (see ) here ). In the plugin menu (clicking on the little puzzle symbol left of the plugin name), select the appropriate engine.","title":"Plugin running on wrong engine"},{"location":"tools-imjoy/#remove-conda-environment","text":"At one point, your conda environment might get corrupted. You can easily remove it, and create a new one Open anaconda terminal Activate base environment : conda activate base Remove fq-segmentation environment : conda env remove --name fq-segmentation","title":"Remove conda environment"},{"location":"tools-imjoy/#reporting-bugs","text":"Detailed installation logs are provided in the console of the browser. Information in this log, can facilitate the correction of encountered bugs. When reporting problems with this package, please provide the log copied to text file. To acces the console log in Chrome : In the ImJoy app mouse-right-click. Select Inspect . This will open a new interface on the right size of your browser windows. Select the panel Console and copy the entire content, and paste it to a file.","title":"Reporting bugs"},{"location":"tools-imjoy/#specify-your-own-jupyter-token","text":"You can specify your own token yourtoken imjoy --jupyter --token yourtoken When launched like this, you will not get the full Jupyter URL in the terminal, but http://localhost:8888/?token=... . When copying this link to the ImJoy app for the first time you have to replace the ... by the token you actually specified. The next time you start jupyter with imjoy --jupyter your custom token will be used","title":"Specify your own Jupyter token"},{"location":"tools-jupyter/","text":"Jupyter notebooks \u00b6 We also provide Jupyter notebooks for certain Python analysis workflows. These notebookd provide an interactive interface to run analysis workflows. For more details, see any of the excellent introductions to Jupyter, e.g. here or here To run these notebooks, we recommend using either Miniconda with Python 3.7 or if you plan on using Python more, Anaconda with Python 3.7 . We further recommend creating a dedicated environment for the Python code to install the code. You can do this from an anaconda terminal. To create and environment named rna-loc-liver containing jupyter type (you only have to do this once): conda create -n rna-loc-liver python=3.7 jupyter To install the analysis code (you only have to do this once): Activate the environment : conda activate rna-loc-liver Install the analysis package and all required packages pip install git+https://github.com/muellerflorian/walesky-rna-loc-liver To open a notebook, open an anaconda terminal in the folder containing the notebook Activate the environment : conda activate rna-loc-liver Navigate to the folder containing the notebook you want to execute. Launch the Jupyter notebook App. . jupyter notebook This will launch a new browser window (or a new tab)showing the Notebook Dashboard, a control panel that allows (among other things) to select which notebook to open. Make sure that the notebook is running in the specified environment (upper right corner of interface). If not change it from the menu \"Kernel\". Click on the name of the notebook that you want to open, and start processing your data.","title":"Jupyter"},{"location":"tools-jupyter/#jupyter-notebooks","text":"We also provide Jupyter notebooks for certain Python analysis workflows. These notebookd provide an interactive interface to run analysis workflows. For more details, see any of the excellent introductions to Jupyter, e.g. here or here To run these notebooks, we recommend using either Miniconda with Python 3.7 or if you plan on using Python more, Anaconda with Python 3.7 . We further recommend creating a dedicated environment for the Python code to install the code. You can do this from an anaconda terminal. To create and environment named rna-loc-liver containing jupyter type (you only have to do this once): conda create -n rna-loc-liver python=3.7 jupyter To install the analysis code (you only have to do this once): Activate the environment : conda activate rna-loc-liver Install the analysis package and all required packages pip install git+https://github.com/muellerflorian/walesky-rna-loc-liver To open a notebook, open an anaconda terminal in the folder containing the notebook Activate the environment : conda activate rna-loc-liver Navigate to the folder containing the notebook you want to execute. Launch the Jupyter notebook App. . jupyter notebook This will launch a new browser window (or a new tab)showing the Notebook Dashboard, a control panel that allows (among other things) to select which notebook to open. Make sure that the notebook is running in the specified environment (upper right corner of interface). If not change it from the menu \"Kernel\". Click on the name of the notebook that you want to open, and start processing your data.","title":"Jupyter notebooks"}]}